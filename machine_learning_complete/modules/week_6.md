# Week 6 Resources: Unsupervised Learning

This chapter will instead focus on unsupervised learning, a set of statistical tools intended for the setting in which we have only a set of features X1,X2, . . . , Xp measured on n observations. We are not interested in prediction, because we do not have an associated response variable Y . Rather, the goal is to discover interesting things about the measurements on X1,X2, . . .,Xp. Is there an informative way to visualize the data? Can we discover subgroups among the variables or among the observations? Unsupervised learning refers to a diverse set of techniques for answering questions such as these.

## Slide
* [Week06 Slide](https://drive.google.com/file/d/1IBG1Da1-C8KbojxAM-NW5DOlV1CjXHpS/view?usp=sharing)

## Objectives

* K-Means Clustering Method
* Hierarchical Clustering
* PCA (Principal Component Analysis)

## Notebook

[Unsupervised Learning Lecture](https://s3-ap-southeast-1.amazonaws.com/intro-to-ml-minhdh/week_6/unsupervised_learning_lecture.ipynb)

<iframe allowfullscreen src="https://www.beautiful.ai/player/-Lam4OAmh_VoibMSZ9Sx/MLC-Week-6?utm_source=beautiful_player&utm_medium=embed&utm_campaign=-Lam4OAmh_VoibMSZ9Sx" height="400" width="100%"></iframe>

## Resources

* [k-means visualization](https://www.naftaliharris.com/blog/visualizing-k-means-clustering)
* [Hierarchical Agglomerative Clustering - Check out this video](https://www.youtube.com/watch?v=OcoE7JlbXvY)
* [A fun paper on using PCA to make sense of the Wikileaks cable release](http://bit.ly/2v0nxrA)
* [PCA Eigenvectors & Eigenvalues](https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues?answertab=votes#tab-top)
